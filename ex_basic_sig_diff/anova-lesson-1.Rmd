---
title: "ANOVA Lesson 1"
author: (Created by P. Lombardo)
output: 
    learnr::tutorial:
        theme: "yeti"
runtime: shiny_prerendered
---

```{r setup, include=FALSE}
library(learnr)
library(car)
library(tidyverse)
knitr::opts_chunk$set(echo = FALSE)

plot_resids_anova<-function(formula, data,dec=3){
    IV<-all.vars(formula)[2]
    DV<-all.vars(formula)[1]
    sds<-tapply(data[[DV]],data[[IV]],sd)
    levs<-levels(data[[IV]])
    aov.model<-aov(formula(paste(DV,IV,sep="~")), data = data)
    M<-max(aov.model$residuals)
    m<-min(aov.model$residuals)
    ggplot(data = data.frame(x=data[[IV]],
                         y=aov.model$residuals),
       aes(x=x,
           y=y,
           color=x))+
    geom_hline(yintercept=0)+
    geom_boxplot(aes(fill=x),alpha=.3, color=NA)+
    # geom_stripchart()
    geom_point(position=position_jitter(width=.1), alpha=.6)+theme_bw()+labs(y="residuals",x="fitted values", title=paste("Residual Versus Fitted Plot,",DV,"~",IV),                                                                    subtitle="(Boxes represent interquartile ranges)")+ scale_y_continuous(limits=c(m-.1,M+.12))+

        scale_color_discrete(IV,labels=paste(levs,"\n(stdev = ",round(sds,dec),")\n",sep=""))+
        scale_fill_discrete(guide="none")
}

```

```{css, echo=FALSE}
details summary { 
  cursor: pointer;
  color: rgb(154, 7, 7);
  font-size: 18px;
  font-style: italic;
  font-family: Georgia;
}
```

## Our research question {data-progressive=TRUE}
Today want to consider the following question:

> Does the ***species*** of an iris plant have an association with the mean width of its ***sepals***?

<center><figure><img src="images/iris.png" width=70%></img>
<figcaption>Fig.1 - Labeled Irises by Species <a href="https://www.datacamp.com/tutorial/machine-learning-in-r">(source)</a></figcaption></figure></center>

### Explore the data!

#### Exercise!
Run the code below to explore the data frame.  Remember you can use the small, black triangle in the upper right to view more variables (columns), and you can hit the "Next" button to view more observations (rows).
```{r explore, exercise = TRUE, exercise.lines = 2}
iris
```

***

#### Reviewing some important definitions
In statistics, it is critical to distinguish between the following types of variables:

* ***Independent variable:***  this is typically a variable that researchers have some control over, and they let it vary to test for some sort of response in the *dependent variable.*

* ***Dependent variable:***  this is typically a variable that researchers use to measure the response to differences in an *independent variable*. The researchers cannot (and should not) control what the dependent variable is doing!

Identifying our independent and dependent variables is a critical step in determining how to proceed with appropriate analyses and visualizations.  With that in mind, let's revisit our research question:

> Does the ***species*** of an iris plant have an association with the mean width of its ***sepals***?

With this in mind, please answer the questions below!

```{r variable-question}
quiz(
    question("Based on the definition above, which variable in the data frame is the *independent variable*? ",
    answer("Sepal.Width", message="This is an important variable, but in this case the scientists are not choosing flowers to get specific sepal widths. They are not exercising any control over this variable."),
    answer("Sepal.Length", message="This variable is not related to our research question. (We did use it as an example though.)"),
    answer("Species", correct = TRUE),
    answer("Petal.Length", message="This variable is not related to our research question."),
    answer("Petal.Width",message="This variable is not related to our research question."),
    answer("Sample_ID", message="This is not a variable in our data frame."),
    allow_retry = T,
    random_answer_order = T,
    incorrect = paste(random_encouragement(),"Remember we are looking for differences in the *sepal* widths between setosa, virginica, and versicolor irises. The scientists specifically collected samples from each species of iris, exercising some control over that aspect of the study."),
    post_message = random_praise()
  ),

    question("Based on the definitions above, which variable in the data frame is the *dependent variable*?",
        answer("Sepal.Width", correct=TRUE),
        answer("Sepal.Length", message="This variable is not related to our research question. (We did use it as an example though.)"),
        answer("Species", message="We do not typically think of the species of a flower as *responding* to the variation in some other variable."),
        answer("Petal.Length", message="This variable is not related to our research question."),
        answer("Petal.Width",message="This variable is not related to our research question."),
        answer("Sample_ID", message="This is not a variable in our data frame."),
        allow_retry = T,
        random_answer_order = T,
        incorrect = paste(random_encouragement(),"Remember we are looking for differences in the *sepal* widths between setosa, virginica, and versicolor irises. The researchers collected different species already; what *measurement* will they use to compare these samples?"),
        post_message = random_praise()
      )
)
```

### Is ANOVA the right approach?
**An**alysis **o**f **Va**riance, or ANOVA, is a common statistical test used to detect associations between a quantitative *dependent variable* (like `Sepal.Width`) and a categorical *independent variable* (like `Species`). 

* By using a null hypothesis of "The population means of all groups are equal," it attempts to use sample data to find evidence that *at least one* group has a different population mean than the rest.
* The "groups" of an ANOVA are recorded using the *independent variable*, where the number of categories for this variable should be three or more. These categories are sometimes called *levels*.

#### Exercise!
How many *levels* does the `Species` variable have? The `levels()` command applied to a factor variable like `Species` will list the different category options, which in our case are the different species in our sample data.  In the code block below, use the `levels()` function on the `Species` column of the `iris` data set.
```{r levels, exercise = TRUE, exercise.lines = 3}
# Place your code here
```
```{r levels-hint-1}
levels(...)
```
```{r levels-hint-2}
levels(iris$...)
```
```{r levels-solution}
levels(iris$Species)
# Or count the levels with length()
length(levels(iris$Species))
```

```{r why-anova-question}
question("Which of the following statements explain(s) why we need to use ANOVA rather than a different statistical test? <br> *Select all that apply.*",
    answer("We are interested in comparing the means for a quantitative measurement across several groups.", correct=TRUE),
    answer("The independent variable is a categorical variable with at least *three* groups (sometimes called \"levels\").", correct = TRUE),
    answer("Each group has a variance we need to analyze.", message = "While the details of ANOVA involve variance, it actually tests for potentially different means."),
    answer("The sample data will show us that the means are different, so we do not need ANOVA.", message = "We would still use ANOVA to do our statistical testing regardless of what the summarized data reports."),
    answer("Both our dependent and independent variables are quantitative.", message = "Our independent variable is not quantititative; we do not need a number to record the species of iris."),
    allow_retry = T,
    random_answer_order = T,
    post_message = random_praise()
  )
```

## Summarizing the data
We have identified `Species` as our independent variable, with a `Sepal.Width` dependent variable. Moreover, we have decided to use ANOVA to analyze our research question. This will help us determine whether the data provides evidence to suggest that there are differences in the *population means* for `Sepal.Width` when we look at our three `Species`.

Before doing inferential statistics, however, we should compute descriptive statistics associated with our sample data. Particularly, we  

1. Look at the *sample means* for sepal width across the three species, and
2. Use a visual, like a box-plot, to further explore whether there appear to be differences in sepal widths between the three species *in our sample*. 

#### Exercise!
The code below generates this explorative information, *but for petal length*. ***Make the appropriate changes to the code to work for `Sepal.Width` instead.***
```{r explore2, exercise = TRUE, exercise.lines = 5}
# Sepal length means by species
tapply(iris$Petal.Length, iris$Species, mean)
# boxplot
boxplot(Petal.Length~Species, data = iris)
```
```{r explore2-hint-1}
# Petal Width means by species
tapply(iris$..., iris$Species, mean)
# boxplot
boxplot(...~Species, data = iris)
```
```{r explore2-hint-2}
# Petal Width means by species
tapply(iris$Sepal.Width, iris$Species, mean)
# boxplot
boxplot(...~Species, data = iris)
```
```{r explore2-solution}
# Petal Width means by species
tapply(iris$Sepal.Width, iris$Species, mean)
# boxplot
boxplot(Sepal.Width~Species, data = iris)
```

```{r smallest-mean-question}
question(
    "Based on the previous exercise, which species of iris has the smallest sample mean sepal width?",
    answer("setosa", message="The mean sepal length for setosa should be about 3.5 inches, which is not the smallest.  Are you sure you selected the correct dependent variable, `Sepal.Length`?"),
    answer("versicolor", correct=TRUE),
    answer("virginica", message="The mean sepal length for viginica should be about 3 inches, which is not the smallest.  Are you sure you selected the correct dependent variable, `Sepal.Length`?"),
    answer("siberian",message="While this is a species of iris, it is not in our data set so it should not be appearing in your sample statistics."),
    allow_retry = T,
    random_answer_order = T,
    post_message = random_praise()
)

```

#### Exercise!

```{r predict-question}
question_text(
  "Based on the sample means and the box-plot alone, do you believe there is a difference in *population mean* sepal lengths among the three species of irises? Use the box-plot and means to support your answer. If you believe there is a difference, discuss which species will be different from one another?<br></br> Submit your answer to see an example written by us! <br></br> (***Note***: all responses are marked 'correct,' so please compare your answer against ours.",
  answer_fn(function(value) {
    if (grepl(".*", value)) {
      correct("Great work writing your prediction! How does yours compare with ours?")
    }
  }), message="The box-plots in our visual all seem reasonably different, with setosa seeming the most different from the other two. Admittedly, there is less of a difference when comparing versicolor and virginica. The differences illustrated by the box-plot are reinforced by the sample means, where setosa has a larger sample mean of about 3.4, whereas versicolor (about 2.8) and virginica (about 3.0) are smaller and more similar to one another. <br></br> So does this mean we will find evidence for a difference in means *at the population level*? Is this a trend we would observe if we collected new samples, or is it just a fluke unique to the sample we happened to collect this time?<br></br> Well, that's not so easy to determine based on these simple summaries, ***which is the whole point of ANOVA*** in the first place! Observing differences in our sample data does not imply we will see the same differences in the populations.  We need *inferential statistics* to do that work responsibly."
)
```

## Reviewing the assumptions of ANOVA
As with all statistical tests, trusting the analysis results require that we verify a few testing assumptions.^[Violating testing assumptions can lead to inflated Type I or Type II errors, which has the unfortunate consequence of sending researchers to look for trends where they don't exist, or fail to look for trends where they do exist.] We have already determined that ANOVA is appropriate, so here are the assumptions for that test:

1. Independence of observations
2. Equal variances for each group (Homoscedasticity)
3. Normal residuals (error terms within each group)

The first assumption, *independence of observations*, is not something for which we can test. Rather, we use the data collection phase to attempt to satisfy this first assumption. Specifically, we want to make sure that each observation comes from a different experimental unit (like a flower), randomly selected from one of the populations of interest.

The second and third assumptions are something we can verify with visualizations and even with further statistical tests.  We will spend the next two sections exploring them before interpreting our analysis. First, however, we should do some small preparation. 


### Preparing for ANOVA
There are two preparation steps to complete before we can check our ANOVA assumptions and interpret our results. We need to check the sample sizes for each group, and we need to fit an initial anova model in `R`.

#### A "Balanced" Design
A *balanced design* in the context of ANOVA essentially means that the number of observations in each group of our independent variable are all about the same. Having a balanced design makes the test more robust to violations of our second and third ANOVA assumptions (equal variances and normal residuals). It is also a good idea to shoot for at least 30 observations for each group.^[Having at least 30 observations for each group helps with our third assumption, normality of residuals, for reasons having to do with the central limit theorem.]  

Use the code block below to pass the `Species` column from the `iris` data set into the `table()` command. This will output sample sizes for each group.
```{r balance, exercise = TRUE, exercise.lines = 2}
#place your code here.
```
```{r balance-hint-1}
table(...)
```
```{r balance-hint-2}
table(iris$...)
```
```{r balance-solution}
table(iris$Species)
```

```{r balance-question}
question_text(
  "Based on the previous output, do you believe we have a \"balanced design\"? Are the sample sizes a large enough size? <br></br> Submit your answer to see an example written by us! <br></br> (***Note***: all responses are marked 'correct,' so please compare your answer against ours.",
  answer_fn(function(value) {
    if (grepl(".*", value)) {
      correct("Thanks for writing an answer. How does your answer compare with ours?")
    }
  }), message="The groups are perfectly balanced, with exactly 50 irises sampled from each species population.  Since all group sizes are above 30, we have a good sample size for each group."
)
```

### Fitting an initial ANOVA model in `R`
Before we can check our assumptions, we need to fit an initial model.  Based on the resutls of our assumption check, we may decide modify our approach and fit a different model.

In `R`, we use the `aov()` function to "fit" an ANOVA.  In its simplest application, which is fine for us, it uses two arguments:

* `formula`: which we use to specify the dependent and independent variables (`Lesion.mm ~ Treatment`), and
* `data`: which we use to identify the data frame with our data (`final_df`).

The syntax is `aov(depend_var ~ indep_var, data = df_name)`.

##### Exercise!
Fill in the code below to fit an ANOVA and save the output to the name `iris.aov`.  The last line calls the saved output so you can see that it worked.
```{r aov-setup}
iris.aov<-aov(Sepal.Width~Species, data =iris)
```

```{r aov1, exercise = TRUE, exercise.lines=3, exercise.setup="aov-setup"}
iris.aov <- aov(...)
iris.aov
```
```{r aov1-hint-1}
iris.aov <- aov(..., data = iris)
iris.aov
```
```{r aov1-hint-2}
iris.aov <- aov(Sepal.Width ~ ..., data = iris)
iris.aov
```
```{r aov1-solution}
iris.aov <- aov(Sepal.Width ~ Species, data = iris)
iris.aov
```
**Answer Check:** You should see some output, but perhaps not what you were expecting.  If this worked, however, you will find `Residual standard error: 0.3396877`.

## Checking for Equal Variances {data-progressive=TRUE}
We have a few methods of checking the equal variances assumption of an ANOVA:

1. Visually, we can look at the spread of the residuals for each group; or
2. We can compute the standard deviation of our dependent variable (`Sepal.Width` in our case) for each group; or
3. We can use Levene's test for equal variances.

In this section, we will present the code for each approach.

### Visually inspecting for equal variances
Using the fitted anova model, `iris.aov`, from the previous section, we can use the `plot()` function in `R` to automatically prepare some diagnostic plots.  For this particular assumption, we only care about the first plot, so we will add `which=1` to the arguments.

Run the code below to generate the appropriate visual.
```{r visual-equal-var, exercise = TRUE, exercise.lines=3, exercise.setup="aov-setup"}
plot(iris.aov, which=1)
```
<details>
<summary> $\blacktriangleright$ Interpreting the plot
</summary>

Above you can see that data points representing residuals on the $y$-axis stack over specific "Fitted Values" on the $x$-axis.

* The "Fitted Values" are simply the sample means computed for each group. You'll notice one group of dots is about 2.7 (which is the sample mean for `versicolor`), another is above about 2.9 (the sample mean for `virginica`), and the last is above 3.4 (the sample mean for `setosa`). The dots are naturally stacked according to their `Species` (more specifically, the sample mean for each species)
* The residuals are simply the sepal width for a given flower minus the sample mean sepal width for that flower's species. In other words, our $y$-axis tracks how far a given sepal width is from its sample mean after grouping by species.

Now that we understand the plot better, we can see that regardless of the species, the general spread of the residuals is about the same. In other words, the different groups of "stacked dots" have about the same vertical spread. This suggests that we do satisfy the equal variances assumption.
</details>


### Comparing standard deviations for each group
Another way to check for equal variances is to compute the standard deviation of `Sepal.Width` for each group, and compare them.  As a heuristic, many suggest using the "three-fold-rule" to gauge whether standard deviations are similar enough.

> The largest standard deviation should not be more than three-times the smallest standard deviation.

To compute standard deviations by group, we can use the functions `group_by()` and `summarize()`  from the `dplyr` package. Recall that  

* `group_by()` is used to specify our grouping variable; our independent variable in this analysis
* inside `summarize()` we can use `R` functions like `sd()` to do our summaries.

Use the code-chunk below to build your table comparing standard deviations for our three species.
```{r equal-var-table, exercise = TRUE, exercise.lines=4}
iris %>%
    group_by(...) %>%
    summarize(stdevs = ...)
```
```{r equal-var-table-hint-1}
iris %>%
    group_by(Species) %>%
    summarize(stdevs = ...)
```
```{r equal-var-table-hint-2}
iris %>%
    group_by(Species) %>%
    summarize(stdevs = sd(...))
```
```{r equal-var-table-solution}
iris %>%
    group_by(Species) %>%
    summarize(stdevs = sd(Sepal.Width))
```


<details> 
<summary> $\blacktriangleright$ Interpretation
</summary>
The smallest standard deviation is about 0.314; tripling this is about 0.9.  Since all the other standard deviations are below 0.9, we satisfy the "three-fold-rule".  Therefore, as a heuristic, we can operate under the assumption that the variances for the groups are equal.
</details>

### Statistical Testing for Equal Variances
There is are several hypothesis tests that involve comparing variances for different groups.  A commonly used test is called [Levene's Test](https://en.wikipedia.org/wiki/Levene%27s_test), but it is important to understand how this test works.

* The *null hypothesis* is that all the variances for the groups are equal.  (This is what we *want*!)
* The *alternative hypothesis* is that at least one group has a difference variance than the rest.

For because of the way the null and alternative hypotheses are set up, we are in the odd position of hoping that we fail to provide evidence against the null hypothesis. In other words,

> Main Idea: when using Levene's test to assess for equal variance, we want to *fail to provide evidence against the null hypothesis*.  We want our $P$-value to be ***greater than 0.05***!

 
Running Levene's test in `R` is straightforward, but we do have to load the `car` package first.^[Make sure `library(car)` appears at the head of your R script or document to load the `car` package.]

```{r}
broom::tidy(leveneTest(Sepal.Width~Species,
           center="mean", data = iris))$p.value
```

P-value < 0.05, indicating we have do not have evidence the variances are  unequal.


## Checking for Normal Residuals
normality
```{r}
# hist(iris.aov$residuals)
ggplot()+
    geom_histogram(aes(x = iris.aov$residuals),
                   fill='dodgerblue',alpha=.6,
                   color='gray4',bins=10)+theme_bw()+labs(x="Residuals",title="Histogram of ANOVA Residuals")
```

```{r}
iris.aov<-aov(Sepal.Width~Species, data =iris)
plot(iris.aov, which =2)
```

```{r}
shapiro.test(iris.aov$residuals)$p.value
```

```{r}
# with(iris,
#      tapply(Sepal.Width, Species, hist))

ggplot(data = iris,
       aes(x = Sepal.Width))+
    geom_histogram(bins =5)+
    facet_grid(Species~., scales="free")
```


## Planning for final analysis
No seeming issues with homoscedasticity or normality of residuals; the design is perfectly balanced, and we have good sample sizes.  A standard ANOVA should do the trick!

## Final analysis and interpretation
```{r}
summary(iris.aov)
```
Evidence suggests at least one population mean is different from the others

```{r}
TukeyHSD(iris.aov)
```

All three appear different from each other

