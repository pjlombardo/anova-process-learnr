---
title: "ANOVA Lesson 1"
author: (Created by P. Lombardo)
output: 
    learnr::tutorial:
        theme: "yeti"
runtime: shiny_prerendered
---

```{r setup, include=FALSE}
library(learnr)
library(car)
# library(dplyr)
library(ggplot2)
knitr::opts_chunk$set(echo = FALSE)

plot_resids_anova<-function(formula, data,dec=3){
    IV<-all.vars(formula)[2]
    DV<-all.vars(formula)[1]
    sds<-tapply(data[[DV]],data[[IV]],sd)
    levs<-levels(data[[IV]])
    aov.model<-aov(formula(paste(DV,IV,sep="~")), data = data)
    M<-max(aov.model$residuals)
    m<-min(aov.model$residuals)
    ggplot(data = data.frame(x=data[[IV]],
                         y=aov.model$residuals),
       aes(x=x,
           y=y,
           color=x))+
    geom_hline(yintercept=0)+
    geom_boxplot(aes(fill=x),alpha=.3, color=NA)+
    # geom_stripchart()
    geom_point(position=position_jitter(width=.1), alpha=.6)+theme_bw()+labs(y="residuals",x="fitted values", title=paste("Residual Versus Fitted Plot,",DV,"~",IV),                                                                    subtitle="(Boxes represent interquartile ranges)")+ scale_y_continuous(limits=c(m-.1,M+.12))+

        scale_color_discrete(IV,labels=paste(levs,"\n(stdev = ",round(sds,dec),")\n",sep=""))+
        scale_fill_discrete(guide="none")
}

```

## Our research question {data-progressive=TRUE}
Today want to consider the following question:

> Does the ***species*** of an iris plant have an association with the mean width of its ***sepals***?

<center><figure><img src="images/iris.png" width=70%></img>
<figcaption>Fig.1 - Labeled Irises by Species <a href="https://www.datacamp.com/tutorial/machine-learning-in-r">(source)</a></figcaption></figure></center>

### Explore the data!

#### Exercise!
Run the code below to explore the data frame.  Remember you can use the small, black triangle in the upper right to view more variables (columns), and you can hit the "Next" button to view more observations (rows).
```{r explore, exercise = TRUE, exercise.lines = 2}
iris
```

***

#### Reviewing some important definitions
In statistics, it is critical to distinguish between the following types of variables:

* ***Independent variable:***  this is typically a variable that researchers have some control over, and they let it vary to test for some sort of response in the *dependent variable.*

* ***Dependent variable:***  this is typically a variable that researchers use to measure the response to differences in an *independent variable*. The researchers cannot (and should not) control what the dependent variable is doing!

Identifying our independent and dependent variables is a critical step in determining how to proceed with appropriate analyses and visualizations.  With that in mind, let's revisit our research question:

> Does the ***species*** of an iris plant have an association with the mean width of its ***sepals***?

With this in mind, please answer the questions below!

```{r variable-question}
quiz(
    question("Based on the definition above, which variable in the data frame is the *independent variable*? ",
    answer("Sepal.Width", message="This is an important variable, but in this case the scientists are not choosing flowers to get specific sepal widths. They are not exercising any control over this variable."),
    answer("Sepal.Length", message="This variable is not related to our research question. (We did use it as an example though.)"),
    answer("Species", correct = TRUE),
    answer("Petal.Length", message="This variable is not related to our research question."),
    answer("Petal.Width",message="This variable is not related to our research question."),
    answer("Sample_ID", message="This is not a variable in our data frame."),
    allow_retry = T,
    random_answer_order = T,
    incorrect = paste(random_encouragement(),"Remember we are looking for differences in the *sepal* widths between setosa, virginica, and versicolor irises. The scientists specifically collected samples from each species of iris, exercising some control over that aspect of the study."),
    post_message = random_praise()
  ),

    question("Based on the definitions above, which variable in the data frame is the *dependent variable*?",
        answer("Sepal.Width", correct=TRUE),
        answer("Sepal.Length", message="This variable is not related to our research question. (We did use it as an example though.)"),
        answer("Species", message="We do not typically think of the species of a flower as *responding* to the variation in some other variable."),
        answer("Petal.Length", message="This variable is not related to our research question."),
        answer("Petal.Width",message="This variable is not related to our research question."),
        answer("Sample_ID", message="This is not a variable in our data frame."),
        allow_retry = T,
        random_answer_order = T,
        incorrect = paste(random_encouragement(),"Remember we are looking for differences in the *sepal* widths between setosa, virginica, and versicolor irises. The researchers collected different species already; what *measurement* will they use to compare these samples?"),
        post_message = random_praise()
      )
)
```

### Is ANOVA the right approach?
**An**alysis **o**f **Va**riance, or ANOVA, is a common statistical test used to detect associations between a quantitative *dependent variable* (like `Sepal.Width`) and a categorical *independent variable* (like `Species`). 

* By using a null hypothesis of "The population means of all groups are equal," it attempts to use sample data to find evidence that *at least one* group has a different population mean than the rest.
* The "groups" of an ANOVA are recorded using the *independent variable*, where the number of categories for this variable should be three or more. These categories are sometimes called *levels*.

#### Exercise!
How many *levels* does the `Species` variable have? The `levels()` command applied to a factor variable like `Species` will list the different category options, which in our case are the different species in our sample data.  In the code block below, use the `levels()` function on the `Species` column of the `iris` data set.
```{r levels, exercise = TRUE, exercise.lines = 3}
# Place your code here
```
```{r levels-hint-1}
levels(...)
```
```{r levels-hint-2}
levels(iris$...)
```
```{r levels-solution}
levels(iris$Species)
# Or count the levels with length()
length(levels(iris$Species))
```

```{r why-anova-question}
question("Which of the following statements explain(s) why we need to use ANOVA rather than a different statistical test? <br> *Select all that apply.*",
    answer("We are interested in comparing the means for a quantitative measurement across several groups.", correct=TRUE),
    answer("The independent variable is a categorical variable with at least *three* groups (sometimes called \"levels\").", correct = TRUE),
    answer("Each group has a variance we need to analyze.", message = "While the details of ANOVA involve variance, it actually tests for potentially different means."),
    answer("The sample data will show us that the means are different, so we do not need ANOVA.", message = "We would still use ANOVA to do our statistical testing regardless of what the summarized data reports."),
    answer("Both our dependent and independent variables are quantitative.", message = "Our independent variable is not quantititative; we do not need a number to record the species of iris."),
    allow_retry = T,
    random_answer_order = T,
    post_message = random_praise()
  )
```

## Summarizing the data
We have identified `Species` as our independent variable, with a `Sepal.Width` dependent variable. Moreover, we have decided to use ANOVA to analyze our research question. This will help us determine whether the data provides evidence to suggest that there are differences in the *population means* for `Sepal.Width` when we look at our three `Species`.

Before doing inferential statistics, however, we should compute descriptive statistics associated with our sample data. Particularly, we  

1. Look at the *sample means* for sepal width across the three species, and
2. Use a visual, like a box-plot, to further explore whether there appear to be differences in sepal widths between the three species *in our sample*. 

#### Exercise!
The code below generates this explorative information, *but for petal length*. ***Make the appropriate changes to the code to work for `Sepal.Width` instead.***
```{r explore2, exercise = TRUE, exercise.lines = 5}
# Sepal length means by species
tapply(iris$Petal.Length, iris$Species, mean)
# boxplot
boxplot(Petal.Length~Species, data = iris)
```
```{r explore2-hint-1}
# Petal Width means by species
tapply(iris$..., iris$Species, mean)
# boxplot
boxplot(...~Species, data = iris)
```
```{r explore2-hint-2}
# Petal Width means by species
tapply(iris$Sepal.Width, iris$Species, mean)
# boxplot
boxplot(...~Species, data = iris)
```
```{r explore2-solution}
# Petal Width means by species
tapply(iris$Sepal.Width, iris$Species, mean)
# boxplot
boxplot(Sepal.Width~Species, data = iris)
```

```{r smallest-mean-question}
question(
    "Based on the previous exercise, which species of iris has the smallest sample mean sepal width?",
    answer("setosa", message="The mean sepal length for setosa should be about 3.5 inches, which is not the smallest.  Are you sure you selected the correct dependent variable, `Sepal.Length`?"),
    answer("versicolor", correct=TRUE),
    answer("virginica", message="The mean sepal length for viginica should be about 3 inches, which is not the smallest.  Are you sure you selected the correct dependent variable, `Sepal.Length`?"),
    answer("siberian",message="While this is a species of iris, it is not in our data set so it should not be appearing in your sample statistics."),
    allow_retry = T,
    random_answer_order = T,
    post_message = random_praise()
)

```

#### Exercise!

```{r predict-question}
question_text(
  "Based on the sample means and the box-plot alone, do you believe there is a difference in *population mean* sepal lengths among the three species of irises? Use the box-plot and means to support your answer. If you believe there is a difference, discuss which species will be different from one another?<br></br> Submit your answer to see an example written by us! <br></br> (***Note***: all responses are marked 'correct,' so please compare your answer against ours.",
  answer_fn(function(value) {
    if (grepl(".*", value)) {
      correct("Great work writing your prediction! How does yours compare with ours?")
    }
  }), message="The box-plots in our visual all seem reasonably different, with setosa seeming the most different from the other two. Admittedly, there is less of a difference when comparing versicolor and virginica. The differences illustrated by the box-plot are reinforced by the sample means, where setosa has a larger sample mean of about 3.4, whereas versicolor (about 2.8) and virginica (about 3.0) are smaller and more similar to one another. <br></br> So does this mean we will find evidence for a difference in means *at the population level*? Is this a trend we would observe if we collected new samples, or is it just a fluke unique to the sample we happened to collect this time?<br></br> Well, that's not so easy to determine based on these simple summaries, ***which is the whole point of ANOVA*** in the first place! Observing differences in our sample data does not imply we will see the same differences in the populations.  We need *inferential statistics* to do that work responsibly."
)
```

### Reviewing the assumptions of ANOVA
As with all statistical tests, trusting the analysis results require that we verify a few testing assumptions.^[Violating testing assumptions can lead to inflated Type I or Type II errors, which has the unfortunate consequence of sending researchers to look for trends where they don't exist, or fail to look for trends where they do exist.] We have already determined that ANOVA is appropriate, so here are the assumptions for that test:

1. Independence of observations
2. Equal variances for each group (Homoscedasticity)
3. Normal residuals (error terms within each group)

The first assumption, *independence of observations*, is not something for which we can test. Rather, we use the data collection phase to attempt to satisfy this first assumption. Specifically, we want to make sure that each observation comes from a different experimental unit (like a flower), randomly selected from one of the populations of interest.

The second and third assumptions are something we can verify with visualizations and even with further statistical tests.  We will spend the next two sections exploring them before interpreting our analysis. First, however, we should do some small preparation. 

### Preparing for ANOVA
There are two preparation steps to complete before we can check our ANOVA assumptions and interpret our results. We need to check the sample sizes for each group, and we need to fit an initial anova model in `R`.

#### A "Balanced" Design
A *balanced design* in the context of ANOVA essentially means that the number of observations in each group of our independent variable are all about the same. Having a balanced design makes the test more robust to violations of our second and third ANOVA assumptions (equal variances and normal residuals). It is also a good idea to shoot for at least 30 observations for each group.^[This helps with our third assumption, normality of residuals, for reasons having to do with the central limit theorem.]  

Use the code block below to pass the `Species` column from the `iris` data set into the `table()` command. This will output sample sizes for each group.
```{r balance, exercise = TRUE, exercise.lines = 2}
#place your code here.
```
```{r balance-hint-1}
table(...)
```
```{r balance-hint-2}
table(iris$...)
```
```{r balance-solution}
table(iris$Species)
```

```{r balance-question}
question_text(
  "Based on the previous output, do you believe we have a \"balanced design\"? Are the sample sizes a large enough size? <br></br> Submit your answer to see an example written by us! <br></br> (***Note***: all responses are marked 'correct,' so please compare your answer against ours.",
  answer_fn(function(value) {
    if (grepl(".*", value)) {
      correct("Thanks for writing an answer. How does your answer compare with ours?")
    }
  }), message="The groups are perfectly balanced, with exactly 50 irises sampled from each species population.  Since all group sizes are above 30, we have a good sample size for each group."
)
```

#### Fitting an initial ANOVA model in `R`


Initial fit
```{r}
iris.aov<-aov(Sepal.Width ~ Species, data = iris)
```


## Checking assumptions, part 1

Checking residuals versus fitted for groups

```{r}
plot_resids_anova<-function(formula, data,dec=3){
    IV<-all.vars(formula)[2]
    DV<-all.vars(formula)[1]
    sds<-tapply(data[[DV]],data[[IV]],sd)
    levs<-levels(data[[IV]])
    aov.model<-aov(formula(paste(DV,IV,sep="~")), data = data)
    M<-max(aov.model$residuals)
    m<-min(aov.model$residuals)
    ggplot(data = data.frame(x=data[[IV]],
                         y=aov.model$residuals),
       aes(x=x,
           y=y,
           color=x))+
    geom_hline(yintercept=0)+
    geom_boxplot(aes(fill=x),alpha=.3, color=NA)+
    # geom_stripchart()
    geom_point(position=position_jitter(width=.1), alpha=.6)+theme_bw()+labs(y="residuals",x="fitted values", title=paste("Residual Versus Fitted Plot,",DV,"~",IV),
                                                                              subtitle="(Boxes represent interquartile ranges)")+ scale_y_continuous(limits=c(m-.1,M+.12))+
    # print(paste(levs," (stdev = ",round(sds,3),")",sep=""))
    # +
        scale_color_discrete(IV,labels=paste(levs,"\n(stdev = ",round(sds,dec),")\n",sep=""))+
        scale_fill_discrete(guide="none")
    
    # annotate("text",x=levs, y=rep(M+.1,length(levs)),
    #          label=paste("stdev =",round(sds,3)))
}

plot_resids_anova(weight~feed, chickwts)
plot_resids_anova(Petal.Width~Species,iris)

```

```{r}
with(iris,
    tapply(Sepal.Width, Species, sd)
)
```


```{r}
leveneTest(Sepal.Width~Species,
           center="mean", data = iris)
```

P-value < 0.05, indicating we have do not have evidence the variances are  unequal.  


## Checking assumptions, part 2
normality
```{r}
hist(iris.aov$residuals)
```

```{r}
library(ggplot2)
iris.aov<-aov(Sepal.Width~Species, data =iris)
plot(iris.aov, which =2)
```

```{r}
shapiro.test(iris.aov$residuals)
```

```{r}
with(iris,
     tapply(Sepal.Width, Species, hist))

library(ggplot2)
ggplot(data = iris,
       aes(x = Sepal.Width))+
    geom_histogram(bins =5)+
    facet_grid(Species~., scales="free")
```


## Planning for final analysis
No seeming issues with homoscedasticity or normality of residuals; the design is perfectly balanced, and we have good sample sizes.  A standard ANOVA should do the trick!

## Final analysis and interpretation
```{r}
summary(iris.aov)
```
Evidence suggests at least one population mean is different from the others

```{r}
TukeyHSD(iris.aov)
```

All three appear different from each other

