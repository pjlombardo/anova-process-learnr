---
title: "ANOVA Lesson 1"
author: (Created by P. Lombardo)
output: 
    learnr::tutorial:
        theme: "united"
runtime: shiny_prerendered
---

```{r setup, include=FALSE}
library(learnr)
library(car)
# library(dplyr)
library(ggplot2)
knitr::opts_chunk$set(echo = FALSE)

plot_resids_anova<-function(formula, data,dec=3){
    IV<-all.vars(formula)[2]
    DV<-all.vars(formula)[1]
    sds<-tapply(data[[DV]],data[[IV]],sd)
    levs<-levels(data[[IV]])
    aov.model<-aov(formula(paste(DV,IV,sep="~")), data = data)
    M<-max(aov.model$residuals)
    m<-min(aov.model$residuals)
    ggplot(data = data.frame(x=data[[IV]],
                         y=aov.model$residuals),
       aes(x=x,
           y=y,
           color=x))+
    geom_hline(yintercept=0)+
    geom_boxplot(aes(fill=x),alpha=.3, color=NA)+
    # geom_stripchart()
    geom_point(position=position_jitter(width=.1), alpha=.6)+theme_bw()+labs(y="residuals",x="fitted values", title=paste("Residual Versus Fitted Plot,",DV,"~",IV),                                                                    subtitle="(Boxes represent interquartile ranges)")+ scale_y_continuous(limits=c(m-.1,M+.12))+

        scale_color_discrete(IV,labels=paste(levs,"\n(stdev = ",round(sds,dec),")\n",sep=""))+
        scale_fill_discrete(guide="none")
}

```

## Our research question {data-progressive=TRUE}
Today want to consider the following question:

> Does the ***species*** of an iris plant have an association with the mean width of its ***sepals***?

<center><figure><img src="images/iris.png" width=70%></img>
<figcaption>Fig.1 - Labeled Irises by Species <a href="https://www.datacamp.com/tutorial/machine-learning-in-r">(source)</a></figcaption></figure></center>

### Explore the data!

#### Exercise!
Run the code below to explore the data frame.  Remember you can use the small, black triangle in the upper right to view more variables (columns), and you can hit the "Next" button to view more observations (rows).
```{r explore, exercise = TRUE, exercise.lines = 2}
iris
```

***

#### Reviewing some important definitions
In statistics, it is critical to distinguish between the following types of variables:

* ***Independent variable:***  this is typically a variable that researchers have some control over, and they let it vary to test for some sort of response in the *dependent variable.*

* ***Dependent variable:***  this is typically a variable that researchers use to measure the response to differences in an *independent variable*. The researchers cannot (and should not) control what the dependent variable is doing!

Identifying our independent and dependent variables is a critical step in determining how to proceed with appropriate analyses and visualizations.  With that in mind, let's revisit our research question:

> Does the ***species*** of an iris plant have an association with the mean width of its ***sepals***?

With this in mind, please answer the questions below!

```{r variable-question}
quiz(
    question("Based on the definition above, which variable in the data frame is the *independent variable*? ",
    answer("Sepal.Width", message="This is an important variable, but the scientists are not choosing flowers to get specific sepal widths. They are not exercising any control over this variable."),
    answer("Sepal.Length", message="This variable is not related to our research question. (We did use it as an example though.)"),
    answer("Species", correct = TRUE),
    answer("Petal.Length", message="This variable is not related to our research question."),
    answer("Petal.Width",message="This variable is not related to our research question."),
    answer("Sample_ID", message="This is not a variable in our data frame."),
    allow_retry = T,
    random_answer_order = T,
    incorrect = paste(random_encouragement(),"Remember we are looking for differences in the *sepal* widths between setosa, virginica, and versicolor irises. The scientists specifically collected samples from each species of iris, exercising some control over that aspect of the study."),
    post_message = random_praise()
  ),

    question("Based on the definitions above, which variable in the data frame is the *dependent variable*?",
        answer("Sepal.Width", correct=TRUE),
        answer("Sepal.Length", message="This variable is not related to our research question. (We did use it as an example though.)"),
        answer("Species", message="We do not typically think of the species of a flower as *responding* to the variation in some other variable."),
        answer("Petal.Length", message="This variable is not related to our research question."),
        answer("Petal.Width",message="This variable is not related to our research question."),
        answer("Sample_ID", message="This is not a variable in our data frame."),
        allow_retry = T,
        random_answer_order = T,
        incorrect = paste(random_encouragement(),"Remember we are looking for differences in the *sepal* widths between setosa, virginica, and versicolor irises. The researchers collected different species already; what *measurement* will they use to compare these samples?"),
        post_message = random_praise()
      )
)
```

### Need something on checking levels
`levels(iris$Species)`

```{r why-anova-question}
question("Which of the following statements explain(s) why we need to use ANOVA rather than a different statistical test? <br> *Select all that apply.*",
    answer("We are interested in comparing the means for a quantitative measurement across several groups.", correct=TRUE),
    answer("The independent variable is a grouping variable with at least *three* groups (sometimes called \"levels\").", correct = TRUE),
    answer("The variance of the groups are all about the same.", message = "While the details of ANOVA involve variance, it does test for differences in means."),
    answer("Our box-plots do not seem to overlap much, and the group means are seemingly different.", message = "We still use ANOVA to do our statistical testing regardless of what the summarized data reports."),
    answer("We should not use an ANOVA for this analysis.", message = "ANOVA is in fact the right analysis approach for this research question and data."),
    allow_retry = T,
    random_answer_order = T,
    post_message = random_praise()
  )
```

## Summarizing the data
We have identified `Species` as our independent variable, with a `Sepal.Width` dependent variable.  So how can we look for an association between these variables?

A common approach is to use a statistical test to determine whether the data provides evidence to suggest that there are differences in the *population mean*  `Sepal.Width`s when we look at our three `Species`.  This, loosely speaking, is what we hope to accomplish when we run an ANOVA. 

However, before doing inferential statistics, we can create descriptive statistics associated with our sample data that help inform our research question. Particularly, we can 

1. Look at the *sample means* for sepal width across the three species, and
2. Use a visual, like a box-plot, to further explore whether there appear to be differences in sepal widths between the three species. 

#### Exercise!
The code below generates this explorative information, *but for petal length*. ***Make the appropriate changes to the code to work for `Sepal.Width` instead.***
```{r explore2, exercise = TRUE, exercise.lines = 5}
# Sepal length means by species
tapply(iris$Petal.Length, iris$Species, mean)
# boxplot
boxplot(Petal.Length~Species, data = iris)
```
```{r explore2-hint-1}
# Petal Width means by species
tapply(iris$..., iris$Species, mean)
# boxplot
boxplot(...~Species, data = iris)
```
```{r explore2-hint-2}
# Petal Width means by species
tapply(iris$Sepal.Width, iris$Species, mean)
# boxplot
boxplot(...~Species, data = iris)
```
```{r explore2-solution}
# Petal Width means by species
tapply(iris$Sepal.Width, iris$Species, mean)
# boxplot
boxplot(Sepal.Width~Species, data = iris)
```

```{r smallest-mean-question}
question(
    "Based on the previous exercise, which species of iris has the smallest sample mean sepal width?",
    answer("setosa", message="The mean sepal length for setosa should be about 3.5 inches, which is not the smallest.  Are you sure you selected the correct dependent variable, `Sepal.Length`?"),
    answer("versicolor", correct=TRUE),
    answer("virginica", message="The mean sepal length for viginica should be about 3 inches, which is not the smallest.  Are you sure you selected the correct dependent variable, `Sepal.Length`?"),
    answer("siberian",message="While this is a species of iris, it is not in our data set so it should not be appearing in your sample statistics."),
    allow_retry = T,
    random_answer_order = T,
    post_message = random_praise()
)

```

#### Exercise!

```{r predict-question}
question_text(
  "Based on the sample means and the box-plot alone, do you believe there is a difference in *population mean* sepal lengths among the three species of irises? Use the box-plot and means to support your answer. If you believe there is a difference, discuss which species will be different from one another?<br></br> Submit your answer to see an example written by us! <br></br> (***Note***: all responses are marked 'correct,' so please compare your answer against ours.",
  answer_fn(function(value) {
    if (grepl(".*", value)) {
      correct("Great work writing your prediction! How does yours compare with ours?")
    }
  }), message="The box-plots in our visual all seem reasonably different, with setosa seeming the most different from the other two. Admittedly, there is less of a difference when comparing versicolor and virginica. The differences illustrated by the box-plot are reinforced by the sample means, where setosa has a larger sample mean of about 3.4, whereas versicolor (about 2.8) and virginica (about 3.0) are smaller and more similar to one another. <br></br> So does this mean we will find evidence for a difference in means *at the population level*? Is this a trend we would observe if we collected new samples, or is it just a fluke unique to the sample we happened to collect this time?<br></br> Well, that's not so easy to determine based on these simple summaries, ***which is the whole point of ANOVA*** in the first place! Observing differences in our sample data does not imply we will see the same differences in the populations.  We need *inferential statistics* to do that work responsibly."
)
```


Acknowledging ANOVA: Even though the sample means may be different, this does not necessarily we have enough evidence that the *population means* are different.


## Preparing for ANOVA

Check for "balance"
```{r}
table(iris$Species)
```

Assumptions of ANOVA:

* Normality of residuals (or normality within groups)
* equal variances/sd within groups

Initial fit
```{r}
iris.aov<-aov(Sepal.Width ~ Species, data = iris)
```


## Checking assumptions, part 1

Checking residuals versus fitted for groups

```{r}
plot_resids_anova<-function(formula, data,dec=3){
    IV<-all.vars(formula)[2]
    DV<-all.vars(formula)[1]
    sds<-tapply(data[[DV]],data[[IV]],sd)
    levs<-levels(data[[IV]])
    aov.model<-aov(formula(paste(DV,IV,sep="~")), data = data)
    M<-max(aov.model$residuals)
    m<-min(aov.model$residuals)
    ggplot(data = data.frame(x=data[[IV]],
                         y=aov.model$residuals),
       aes(x=x,
           y=y,
           color=x))+
    geom_hline(yintercept=0)+
    geom_boxplot(aes(fill=x),alpha=.3, color=NA)+
    # geom_stripchart()
    geom_point(position=position_jitter(width=.1), alpha=.6)+theme_bw()+labs(y="residuals",x="fitted values", title=paste("Residual Versus Fitted Plot,",DV,"~",IV),
                                                                              subtitle="(Boxes represent interquartile ranges)")+ scale_y_continuous(limits=c(m-.1,M+.12))+
    # print(paste(levs," (stdev = ",round(sds,3),")",sep=""))
    # +
        scale_color_discrete(IV,labels=paste(levs,"\n(stdev = ",round(sds,dec),")\n",sep=""))+
        scale_fill_discrete(guide="none")
    
    # annotate("text",x=levs, y=rep(M+.1,length(levs)),
    #          label=paste("stdev =",round(sds,3)))
}

plot_resids_anova(weight~feed, chickwts)
plot_resids_anova(Petal.Width~Species,iris)

```

```{r}
with(iris,
    tapply(Sepal.Width, Species, sd)
)
```


```{r}
leveneTest(Sepal.Width~Species,
           center="mean", data = iris)
```

P-value < 0.05, indicating we have do not have evidence the variances are  unequal.  


## Checking assumptions, part 2
normality
```{r}
hist(iris.aov$residuals)
```

```{r}
library(ggplot2)
iris.aov<-aov(Sepal.Width~Species, data =iris)
plot(iris.aov, which =2)
```

```{r}
shapiro.test(iris.aov$residuals)
```

```{r}
with(iris,
     tapply(Sepal.Width, Species, hist))

library(ggplot2)
ggplot(data = iris,
       aes(x = Sepal.Width))+
    geom_histogram(bins =5)+
    facet_grid(Species~., scales="free")
```


## Planning for final analysis
No seeming issues with homoscedasticity or normality of residuals; the design is perfectly balanced, and we have good sample sizes.  A standard ANOVA should do the trick!

## Final analysis and interpretation
```{r}
summary(iris.aov)
```
Evidence suggests at least one population mean is different from the others

```{r}
TukeyHSD(iris.aov)
```

All three appear different from each other

